{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/poojitha1502/nlp--/blob/main/NLP_Lab_08_08_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oaH4D5EnWg_",
        "outputId": "2ca638ca-9f83-4fea-8941-99e4cf2abada"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 3 rows of the sample resumes:\n",
            "                                         Resume_Text\n",
            "0  I am a software engineer with 5+ years of expe...\n",
            "1  Data Scientist with expertise in Python, R, an...\n",
            "2  A marketing specialist with a background in di...\n",
            "\n",
            "Checking for noisy characters...\n",
            "\n",
            " present: True\n",
            "• present: True\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = {'Resume_Text': [\n",
        "    \"I am a software engineer with 5+ years of experience. My skills include Python, Java, and C++. I have worked on projects involving machine learning and web development.\\n I am an excellent team player.\",\n",
        "    \"Data Scientist with expertise in Python, R, and SQL. I have experience in statistical analysis, data visualization, and building predictive models. • Published a paper on a new machine learning algorithm.\",\n",
        "    \"A marketing specialist with a background in digital marketing, social media management, and content creation. Skills: SEO, SEM, Adobe Photoshop. I have a proven track record of increasing brand visibility.\"\n",
        "]}\n",
        "resumes_df = pd.DataFrame(data)\n",
        "\n",
        "print(\"First 3 rows of the sample resumes:\")\n",
        "print(resumes_df.head(3))\n",
        "print(\"\\nChecking for noisy characters...\")\n",
        "print(f\"\\n present: {'\\n' in resumes_df['Resume_Text'].iloc[0]}\")\n",
        "print(f\"• present: {'•' in resumes_df['Resume_Text'].iloc[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "def preprocess_nltk(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [token for token in tokens if token not in stop_words and len(token) > 1]\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
        "    return stemmed_tokens\n",
        "\n",
        "resumes_df['nltk_tokens'] = resumes_df['Resume_Text'].apply(preprocess_nltk)\n",
        "\n",
        "all_nltk_tokens = [token for sublist in resumes_df['nltk_tokens'] for token in sublist]\n",
        "fdist_nltk = nltk.FreqDist(all_nltk_tokens)\n",
        "top_10_nltk = fdist_nltk.most_common(10)\n",
        "\n",
        "print(\"\\n--- NLTK Preprocessing Results ---\")\n",
        "print(\"Processed Tokens for first resume:\")\n",
        "print(resumes_df['nltk_tokens'].iloc[0])\n",
        "print(\"\\nTop 10 frequent stemmed words:\")\n",
        "print(top_10_nltk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UARcaA40nrYY",
        "outputId": "8efd1a93-8a86-4c64-8af9-eab19d5f2c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- NLTK Preprocessing Results ---\n",
            "Processed Tokens for first resume:\n",
            "['softwar', 'engin', 'year', 'experi', 'skill', 'includ', 'python', 'java', 'work', 'project', 'involv', 'machin', 'learn', 'web', 'develop', 'excel', 'team', 'player']\n",
            "\n",
            "Top 10 frequent stemmed words:\n",
            "[('experi', 2), ('skill', 2), ('python', 2), ('machin', 2), ('learn', 2), ('data', 2), ('market', 2), ('softwar', 1), ('engin', 1), ('year', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\"Downloading spaCy model 'en_core_web_sm'...\")\n",
        "    from spacy.cli import download\n",
        "    download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess_spacy(text):\n",
        "    doc = nlp(text)\n",
        "    lemmas = [token.lemma_.lower() for token in doc if token.is_alpha and token.pos_ in ['NOUN', 'VERB']]\n",
        "    return lemmas\n",
        "\n",
        "resumes_df['spacy_lemmas'] = resumes_df['Resume_Text'].apply(preprocess_spacy)\n",
        "\n",
        "all_spacy_lemmas = [lemma for sublist in resumes_df['spacy_lemmas'] for lemma in sublist]\n",
        "fdist_spacy = nltk.FreqDist(all_spacy_lemmas)\n",
        "top_10_spacy = fdist_spacy.most_common(10)\n",
        "\n",
        "print(\"\\n--- spaCy Preprocessing Results ---\")\n",
        "print(\"Processed Lemmas for first resume:\")\n",
        "print(resumes_df['spacy_lemmas'].iloc[0])\n",
        "print(\"\\nTop 10 frequent lemmas:\")\n",
        "print(top_10_spacy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taUZvIKinvYU",
        "outputId": "c0441af5-5cc6-4dc7-a30e-e91c9cff1667"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- spaCy Preprocessing Results ---\n",
            "Processed Lemmas for first resume:\n",
            "['software', 'engineer', 'year', 'experience', 'skill', 'include', 'work', 'project', 'involve', 'machine', 'learning', 'web', 'development', 'team', 'player']\n",
            "\n",
            "Top 10 frequent lemmas:\n",
            "[('experience', 2), ('skill', 2), ('machine', 2), ('have', 2), ('marketing', 2), ('software', 1), ('engineer', 1), ('year', 1), ('include', 1), ('work', 1)]\n"
          ]
        }
      ]
    }
  ]
}